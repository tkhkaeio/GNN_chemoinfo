{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wx0WW6OZo8zv"
   },
   "source": [
    "# Gaussian Mixture Model:GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y40k8CJMo8zw"
   },
   "source": [
    "Define GMM as a mixture model which raito is $\\pi_k$\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{x} | \\boldsymbol{\\pi}, \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})=\\sum_{k=1}^{K} {\\pi_{k}}{\\mathcal{N}}\\left(\\boldsymbol{x} | \\boldsymbol{\\mu}_{k}, \\boldsymbol{\\Sigma}_{k}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XGWUxQ1o8zw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import scipy as sp\n",
    "from scipy import stats as st\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rc\n",
    "import matplotlib.animation as ani\n",
    "import imageio\n",
    "import glob\n",
    "from PIL import Image\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1837,
     "status": "ok",
     "timestamp": 1563261416263,
     "user": {
      "displayName": "take ohkawa",
      "photoUrl": "",
      "userId": "16951519727071626468"
     },
     "user_tz": -540
    },
    "id": "QxDa6zHso8z0",
    "outputId": "7d035309-27c4-4712-f3df-47000222085d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check:  0 [0. 0.] [[1. 0.]\n",
      " [0. 2.]] 2.0\n",
      "check:  1 [8. 4.] [[1. 0.]\n",
      " [0. 1.]] 1.0\n",
      "check:  2 [16. 16.] [[1.16516742 1.04517218]\n",
      " [1.04517218 1.70517305]] 0.8944271909999172\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "n = [300, 500, 600]\n",
    "N = np.sum(n)\n",
    "mu_true = np.asanyarray(\n",
    "     [[0, 0],\n",
    "      [8., 4.],\n",
    "      [16., 16.]])\n",
    "\n",
    "D = mu_true.shape[1]\n",
    "\n",
    "sigma_true = np.asanyarray(\n",
    "        [ sp.linalg.sqrtm(np.diag((1,4))),\n",
    "          [[1.,0],[0, 1.]],\n",
    "          sp.linalg.sqrtm([[2.45,3],[3,4]])\n",
    "        ])\n",
    "c = ['r', 'g', 'b']\n",
    "\n",
    "rd.seed(seed)\n",
    "org_data = None\n",
    "for i in range(3):\n",
    "    print(\"check: \", i, mu_true[i], sigma_true[i], np.linalg.det(sigma_true[i]))\n",
    "    if org_data is None: org_data = np.c_[st.multivariate_normal.rvs(mean=mu_true[i], cov=sigma_true[i], size=n[i]), np.ones(n[i])*i]\n",
    "    else:                org_data = np.r_[org_data, np.c_[st.multivariate_normal.rvs(mean=mu_true[i], cov=sigma_true[i], size=n[i]), np.ones(n[i])*i]]\n",
    "# plot generated data        \n",
    "plt.figure(figsize=(14, 6))\n",
    "for i in range(3): plt.scatter(org_data[org_data[:,2]==i][:,0], org_data[org_data[:,2]==i][:,1], s=10, c=c[i], alpha=0.3)\n",
    "    \n",
    "# drop true cluster label\n",
    "X = org_data[:,0:2].copy()\n",
    "y = org_data[:,2].copy()\n",
    "labels = [\"r\" if i==0 else \"g\" if i==1 else \"b\" for i in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3FOSwBOo8z4"
   },
   "source": [
    "## Two Types of Data\n",
    "Complete data: when we know position X and latent variable Z  \n",
    "Inceomplete data: when we only know position X\n",
    "\n",
    "latent variable z $\\in$ Z is a K dim vector denoting whether observed points belong to some cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyB9aZpco8z5"
   },
   "source": [
    "## EM algorithsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kdEXz45o8z5"
   },
   "source": [
    "1. Initialization: set initial values to π,μ,Σ parameters and compute log likelihood.\n",
    "\n",
    "2. E step:  computete responsibility γ(z_nk)\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\gamma\\left(z_{n k}\\right) &=p\\left(z_{k}=1 | \\boldsymbol{x}\\right) \\\\ &=\\frac{p\\left(z_{k}=1\\right) p\\left(\\boldsymbol{x} | z_{k}=1\\right)}{\\sum_{j=1}^{K} p\\left(z_{k}=1\\right) p\\left(\\boldsymbol{x} | z_{k}=1\\right)} \\\\ &=\\frac{\\pi_{k} \\mathcal{N}\\left(\\boldsymbol{x} | \\boldsymbol{\\mu}_{k}, \\Sigma_{k}\\right)}{\\sum_{j=1}^{K} \\pi_{j} \\mathcal{N}\\left(\\boldsymbol{x} | \\boldsymbol{\\mu}_{j}, \\Sigma_{j}\\right)} \\end{aligned}\n",
    "$$\n",
    "\n",
    "3. M step:  differentiate log likelihood function to π,μ,Σ, and find a maximum likelihood solution.\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\boldsymbol{\\mu}_{k}^{*} &=\\frac{1}{N_{k}} \\sum_{n=1}^{N} \\gamma\\left(z_{n k}\\right) \\boldsymbol{x}_{n} \\\\ \\boldsymbol{\\Sigma}_{k}^{*} &=\\frac{1}{N_{k}} \\sum_{n=1}^{N} \\gamma\\left(z_{n k}\\right)\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}_{k}\\right)\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}_{k}\\right)^{T} \\\\ \\pi_{k} &=\\frac{N_{k}}{N}=\\frac{\\sum_{n=1}^{N} \\gamma\\left(z_{n k}\\right)}{N} \\end{aligned}\n",
    "$$\n",
    "\n",
    "4. Convergence Check: compute log likelihood again. if the difference to the previous one is not smaller than a convergence condition, go back to 2, else exit.\n",
    "\n",
    "$$\n",
    "L_{\\text { new }}=\\ln p(X | \\boldsymbol{\\pi}, \\boldsymbol{\\mu}, \\mathbf{\\Sigma})=\\sum_{n=1}^{N} \\ln \\left\\{\\sum_{j=1}^{K} \\pi_{j} \\mathcal{N}\\left(\\boldsymbol{x}_{n} | \\boldsymbol{\\mu}_{j}, \\boldsymbol{\\Sigma}_{j}\\right)\\right\\}\n",
    "$$\n",
    "$$\n",
    "L_{\\mathrm{new}}-L_{\\mathrm{old}}<\\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzHeUzmXo8z6"
   },
   "outputs": [],
   "source": [
    "class GaussianMixtureModel:\n",
    "    def __init__(self, K, diag=False):\n",
    "        self.K = K\n",
    "        self.diag = diag\n",
    "        self.Pi = None\n",
    "        self.Mu = None\n",
    "        self.Sigma = None\n",
    "                \n",
    "    def _init_params(self, X, random_state=None):\n",
    "        '''\n",
    "        Method for initializing model parameterse based on the size and variance of the input data array. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        '''\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        rnd = np.random.RandomState(seed=random_state)\n",
    "        \n",
    "        self.Pi = np.ones(self.K)/self.K\n",
    "        self.Mu = X[rnd.choice(n_samples, size=self.K, replace=False)]\n",
    "        self.Sigma = np.tile(np.diag(np.var(X, axis=0)), (self.K, 1, 1))\n",
    "\n",
    "        \n",
    "    def _calc_nmat(self, X):\n",
    "        '''\n",
    "        Method for calculating array corresponding $\\mathcal{N}(x_n | \\mu_k)$\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        Nmat : 2D numpy array\n",
    "            2-D numpy array representing probability density for each sample and each component, \n",
    "            where Nmat[n, k] = $\\mathcal{N}(x_n | \\mu_k)$.\n",
    "        \n",
    "        '''\n",
    "        n_samples, n_features = np.shape(X)\n",
    "         \n",
    "        Diff = np.reshape(X, (n_samples, 1, n_features) ) - np.reshape(self.Mu, (1, self.K, n_features) )\n",
    "        L = np.linalg.inv(self.Sigma)\n",
    "        exponent = np.einsum(\"nkj,nkj->nk\", np.einsum(\"nki,kij->nkj\", Diff, L), Diff)\n",
    "        Nmat = np.exp(-0.5*exponent)/np.sqrt(np.linalg.det(self.Sigma))   / (2*np.pi)**(n_features/2)\n",
    "        return Nmat\n",
    "        \n",
    "    def _Estep(self, X):\n",
    "        '''\n",
    "        Method for calculating the array corresponding to responsibility.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        Gam : 2D numpy array\n",
    "            2-D numpy array representing responsibility of each component for each sample in X, \n",
    "            where Gamt[n, k] = $\\gamma_{n, k}$.\n",
    "        \n",
    "        '''\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        Nmat = self._calc_nmat(X)\n",
    "        tmp = Nmat * self.Pi\n",
    "        Gam = tmp/np.reshape(np.sum(tmp, axis=1), (n_samples, 1) )\n",
    "        return Gam\n",
    "        \n",
    "    def _Mstep(self, X, Gam):\n",
    "        '''\n",
    "        Method for calculating the model parameters based on the responsibility gamma.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        Gam : 2D numpy array\n",
    "            2-D numpy array representing responsibility of each component for each sample in X, \n",
    "            where Gamt[n, k] = $\\gamma_{n, k}$.\n",
    "        '''\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        Diff = np.reshape(X, (n_samples, 1, n_features) ) - np.reshape(self.Mu, (1, self.K, n_features) )\n",
    "        Nk = np.sum(Gam, axis=0)\n",
    "        self.Pi = Nk/n_samples\n",
    "        self.Mu = Gam.T @ X / np.reshape(Nk, (self.K, 1))\n",
    "        self.Sigma = np.einsum(\"nki,nkj->kij\", np.einsum(\"nk,nki->nki\", Gam, Diff), Diff)/np.reshape(Nk, (self.K, 1, 1))\n",
    "        if self.diag: \n",
    "            for k in range(self.K):\n",
    "                self.Sigma[k] = np.diag(np.diag(self.Sigma[k]))\n",
    "        \n",
    "    def calc_prob_density(self, X):\n",
    "        '''\n",
    "        Method for calculating the probablity density $\\sum_k \\pi_k \\mathcal{N}(x_n | \\mu_k)$\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        prob_density : 2D numpy array\n",
    "\n",
    "        '''\n",
    "        prob_density = self._calc_nmat(X) @ self.Pi\n",
    "        return prob_density\n",
    "        \n",
    "        \n",
    "    def calc_log_likelihood(self, X):\n",
    "        '''\n",
    "        Method for calculating the log-likelihood for the input X and current model parameters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        Returns\n",
    "        ----------\n",
    "        loglikelihood : float\n",
    "            The log-likelihood of the input data X with respect to current parameter set.\n",
    "        \n",
    "        '''\n",
    "        log_likelihood = np.sum(np.log(self.calc_prob_density(X)))\n",
    "        return log_likelihood\n",
    "        \n",
    "        \n",
    "    def fit(self, X, max_iter, tol, disp_message, random_state=None):\n",
    "        '''\n",
    "        Method for performing learning. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        max_iter : int\n",
    "            Maximum number of iteration\n",
    "        tol : float, positive\n",
    "            Precision. If the change of parameter is below this value, the iteration is stopped\n",
    "        disp_message : Boolean\n",
    "            Whether or not to show the message about the number of iteration\n",
    "        '''\n",
    "        self._init_params(X, random_state=random_state)\n",
    "        LL = []\n",
    "        log_likelihood = - np.float(\"inf\")\n",
    "        for i in range(max_iter):\n",
    "            Gam = self._Estep(X)\n",
    "            self._Mstep(X, Gam)\n",
    "            log_likelihood_old = log_likelihood\n",
    "            log_likelihood = self.calc_log_likelihood(X)\n",
    "            self.plot_log(X, Gam, LL, i)\n",
    "            if  log_likelihood - log_likelihood_old < tol: break\n",
    "                \n",
    "        if disp_message:\n",
    "            m = calc_param(self.diag, self.K, dim=2)\n",
    "            BIC = calc_BIC(log_likelihood,len(X), self.diag, self.K, dim=2)\n",
    "            print(f\"K : {self.K}\")\n",
    "            print(f\"m : {m}\")\n",
    "            print(f\"n_iter : {i}\")\n",
    "            print(f\"log_likelihood : {log_likelihood:.3f}\") \n",
    "            print(f\"BIC : {BIC:.3f}\") \n",
    "            print(\"\")\n",
    "\n",
    "        return BIC\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Method for calculating the array corresponding to responsibility. Just a different name for _Estep\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "            \n",
    "        Returns \n",
    "        ----------\n",
    "        Gam : 2D numpy array\n",
    "            2-D numpy array representing responsibility of each component for each sample in X, \n",
    "            where Gamt[n, k] = $\\gamma_{n, k}$.\n",
    "        \n",
    "        '''\n",
    "        Gam = self._Estep(X)\n",
    "        return Gam\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Method for make prediction about which cluster input points are assigned to.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        pred : 1D numpy array\n",
    "            1D numpy array, with dtype=int, representing which class input points are assigned to.\n",
    "        '''\n",
    "        pred = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return pred\n",
    "    \n",
    "    def plot_log(self,X,Gam,LL,i):\n",
    "        '''\n",
    "        Method for plot a log to each iteration\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2-D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        Gam : 2D numpy array\n",
    "            2-D numpy array representing responsibility of each component for each sample in X, \n",
    "            where Gamt[n, k] = $\\gamma_{n, k}$.\n",
    "        LL : list\n",
    "        log likelihood\n",
    "        i : int\n",
    "        epoch \n",
    "        '''\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        xx, yy = get_meshgrid(X[:, 0], X[:, 1], nx=100, ny=100, margin=0.1)\n",
    "        XX = np.array([xx.ravel(), yy.ravel()]).T\n",
    "        ll = self.calc_prob_density(XX).reshape(xx.shape)\n",
    "        LL.append(np.sum(ll))\n",
    "        im = plt.contour(xx, yy, -ll, alpha=1, zorder=-100, linewidths=0.7, levels=70)  \n",
    "        plt.title(\"step %d\"%i)\n",
    "        #plt.savefig(\"images/gmm_K%d_diag%d/%02d.png\"%(self.K,self.diag,i))\n",
    "        plt.cla()\n",
    "        im2 = plt.plot(LL)\n",
    "        plt.title(\"log-likelihood\")\n",
    "        plt.xlabel(\"step\")\n",
    "        #fig.savefig(\"images/gmm2_K%d_diag%d/%02d.png\"%(self.K,self.diag,i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2wwAanoo8z8"
   },
   "outputs": [],
   "source": [
    "def get_meshgrid(x, y, nx, ny, margin=0.1):\n",
    "    x_min, x_max = (1 + margin) * x.min() - margin * x.max(), (1 + margin) * x.max() - margin * x.min()\n",
    "    y_min, y_max = (1 + margin) * y.min() - margin * y.max(), (1 + margin) * y.max() - margin * y.min()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),\n",
    "                         np.linspace(y_min, y_max, ny))\n",
    "    return xx, yy\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=labels, s=10, alpha=0.5)\n",
    "xx, yy = get_meshgrid(X[:, 0], X[:, 1], nx=N//2, ny=N//2, margin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ls6776BYo80A"
   },
   "outputs": [],
   "source": [
    "def plot_predicted_label(ax, clf, xx, yy, X, t):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.7)\n",
    "    ax.scatter(X[:,0], X[:,1], c=t, s=10, alpha=0.5)\n",
    "    \n",
    "def plot_prob_density(ax, model, xx, yy, X, t):\n",
    "    Z = model.calc_prob_density(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.scatter(X[:,0], X[:,1], c=t, s=10, alpha=0.5)\n",
    "    ax.contour(xx, yy, Z)\n",
    "    \n",
    "def plot_result(model, xx, yy, X, t, K=0, diag=False):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = fig.add_subplot(121)\n",
    "    plt.title(\"result_label_K%d_diag%d\"%(K,diag))\n",
    "    plot_predicted_label(ax, model, xx, yy, X, t)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.title(\"result_dist_K%d_diag%d\"%(K,diag))\n",
    "    plot_prob_density(ax, model, xx, yy, X, t)\n",
    "    fig.savefig(\"result/result_K%d_diag%d.png\"%(K, diag))\n",
    "    \n",
    "def calc_param(diag, K, dim=2):    \n",
    "    if diag: m = 2*dim * K + K #mu,sigma + pi\n",
    "    else: m = dim*(dim+3) * K/2 + K  #mu,sigma + pi\n",
    "    return m\n",
    "\n",
    "def calc_BIC(ll, n, diag, K, dim=2):\n",
    "    m = calc_param(diag, K, dim)\n",
    "    return -2*ll + m*np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16513,
     "status": "ok",
     "timestamp": 1563263124511,
     "user": {
      "displayName": "take ohkawa",
      "photoUrl": "",
      "userId": "16951519727071626468"
     },
     "user_tz": -540
    },
    "id": "4V2zzM60o80C",
    "outputId": "95aff0c6-542c-4a27-8a77-bc918d3af1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K : 1\n",
      "m : 6.0\n",
      "n_iter : 2\n",
      "log_likelihood : -7699.809\n",
      "BIC : 15443.084\n",
      "\n",
      "K : 2\n",
      "m : 12.0\n",
      "n_iter : 13\n",
      "log_likelihood : -6152.370\n",
      "BIC : 12391.671\n",
      "\n",
      "K : 3\n",
      "m : 18.0\n",
      "n_iter : 24\n",
      "log_likelihood : -5451.755\n",
      "BIC : 11033.906\n",
      "\n",
      "K : 4\n",
      "m : 24.0\n",
      "n_iter : 29\n",
      "log_likelihood : -5448.348\n",
      "BIC : 11070.557\n",
      "\n",
      "K : 5\n",
      "m : 30.0\n",
      "n_iter : 29\n",
      "log_likelihood : -5446.084\n",
      "BIC : 11109.494\n",
      "\n",
      "K : 1\n",
      "m : 5\n",
      "n_iter : 2\n",
      "log_likelihood : -9274.189\n",
      "BIC : 18584.600\n",
      "\n",
      "K : 2\n",
      "m : 10\n",
      "n_iter : 8\n",
      "log_likelihood : -6884.938\n",
      "BIC : 13842.319\n",
      "\n",
      "K : 3\n",
      "m : 15\n",
      "n_iter : 10\n",
      "log_likelihood : -5702.959\n",
      "BIC : 11514.582\n",
      "\n",
      "K : 4\n",
      "m : 20\n",
      "n_iter : 29\n",
      "log_likelihood : -5700.893\n",
      "BIC : 11546.671\n",
      "\n",
      "K : 5\n",
      "m : 25\n",
      "n_iter : 29\n",
      "log_likelihood : -5699.974\n",
      "BIC : 11581.054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"result\",exist_ok=True)\n",
    "diags = [False, True]\n",
    "Ks = [1,2,3,4,5]\n",
    "BICs = []\n",
    "for diag in diags:\n",
    "    for K in Ks:\n",
    "        gmm = GaussianMixtureModel(K=K, diag=diag)\n",
    "        os.makedirs(\"images\",exist_ok=True)\n",
    "        os.makedirs(\"images/gmm_K%d_diag%d\"%(K,diag),exist_ok=True)\n",
    "        os.makedirs(\"images/gmm2_K%d_diag%d\"%(K,diag),exist_ok=True)\n",
    "        BIC = gmm.fit(X, max_iter=30, tol=1e-3, disp_message=True, random_state=3)\n",
    "        BICs.append(BIC)\n",
    "        #plot_result(gmm, xx, yy, X, labels, K, diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1563263356071,
     "user": {
      "displayName": "take ohkawa",
      "photoUrl": "",
      "userId": "16951519727071626468"
     },
     "user_tz": -540
    },
    "id": "GBah0X-juysg",
    "outputId": "de263a58-b7ac-4521-a96c-7c50575f4666"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohkawatakehiko/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.plot(Ks, BICs[:5], label=\"cov: full\")\n",
    "plt.plot(Ks, BICs[5:], label=\"cov: diag\")\n",
    "plt.ylabel(\"BIC\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.xticks(Ks)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"result/BIC2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHNMey_vo80F"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"gif\",exist_ok=True)\n",
    "\n",
    "def create_gif(filenames, duration, name=None):\n",
    "    images = []\n",
    "    filenames = sorted(glob.glob(filenames+\"/*\"))\n",
    "    #print(filenames)\n",
    "    for filename in filenames:\n",
    "        try: images.append(Image.open(filename))\n",
    "        except: pass\n",
    "    output_file = 'gif/gif_%s.gif' %(name)\n",
    "    imageio.mimsave(output_file, images, duration=duration)\n",
    "for diag in diags:\n",
    "    for K in Ks:\n",
    "        create_gif(\"images/gmm_K%d_diag%d\"%(K,diag), duration=0.4, name=\"K%d_diag%d_dist\"%(K,diag))\n",
    "        create_gif(\"images/gmm2_K%d_diag%d\"%(K,diag), duration=0.4, name=\"K%d_diag%d_loss\"%(K,diag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3puHd66o80H"
   },
   "source": [
    "## Reference\n",
    "Pattern Recognition and Machine Learning chap.9(https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book)\n",
    "\n",
    "Fitting Gaussian Mixture Model with Expectatoin Maximization Algorithm(https://nbviewer.jupyter.org/github/amber-kshz/PRML/blob/master/notebooks/Ch09_EM_Algorithm_for_Gaussian_Mixture_Model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2d9W-kBBo80I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GMM.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
